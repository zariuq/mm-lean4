# Monad Lifting in Lean 4: Expert Explanation

**Source:** ChatGPT-5 / Lean Zulip expert response
**Date:** 2025-10-13
**Context:** Resolving the Phase 3 Session 1 blocker on `viewStack` and `mapM`

## The Core Issue

**There is NO automatic lifting from total functions to monadic functions in Lean 4.**

If you pass a total `toExpr : Formula ‚Üí Expr` to `List.mapM`, Lean infers `m := Id`, giving you a plain `List Expr`, not `Option (List Expr)`. It will NOT silently wrap via `pure`.

## The Three Solutions for viewStack

```lean
-- Option A: Use partial function (RECOMMENDED) ‚úÖ
-- This is what we implemented in Session 2
def viewStack (stk : Array Formula) : Option (List Expr) :=
  stk.toList.mapM toExprOpt  -- toExprOpt : Formula ‚Üí Option Expr

-- Option B: Explicit lifting with pure/some
def viewStack (stk : Array Formula) : Option (List Expr) :=
  stk.toList.mapM (m := Option) (fun f => some (toExpr f))

-- Option C: Skip mapM entirely
def viewStack (stk : Array Formula) : Option (List Expr) :=
  some (stk.toList.map toExpr)
```

**We chose Option A** in Session 2, which is the cleanest for fail-fast semantics.

## Why Lean Behaves This Way

```lean
mapM : {m : Type ‚Üí Type} ‚Üí [Monad m] ‚Üí (Œ± ‚Üí m Œ≤) ‚Üí List Œ± ‚Üí m (List Œ≤)
```

Lean infers `m` from either:
1. The type of the function argument `(Œ± ‚Üí m Œ≤)`, OR
2. The expected result type

If you pass a total `Œ± ‚Üí Œ≤`, Lean solves by `m := Id`. **There is no rule** "if `m` is `Option` then magically wrap with `pure`".

## Practical Proof Patterns

### Pattern 1: Normalization Lemma for Pure Lifting

```lean
@[simp] lemma List.mapM_pure (xs : List Œ±) (f : Œ± ‚Üí Œ≤) :
  xs.mapM (m := Option) (fun a => some (f a)) = some (xs.map f) := by
  induction xs <;> simp [*]
```

This avoids `mapM.loop` entirely! After rewriting, all standard `map/append/take/dropLast` lemmas apply.

### Pattern 2: Append Lemma (Already in KernelExtras!)

```lean
@[simp] lemma List.mapM_append (f : Œ± ‚Üí Option Œ≤) (xs ys : List Œ±) :
  (xs ++ ys).mapM f = do
    xs' ‚Üê xs.mapM f
    ys' ‚Üê ys.mapM f
    pure (xs' ++ ys') := by
  induction xs <;> simp [*]
```

**We already have this** in KernelExtras.lean at line 168! ‚úÖ

### Pattern 3: Length Preservation

```lean
lemma mapM_length_option {f : Œ± ‚Üí Option Œ≤}
    {xs : List Œ±} {ys : List Œ≤}
    (h : xs.mapM f = some ys) : ys.length = xs.length := by
  revert ys; induction xs with
  | nil => intro ys; simpa using h
  | cons x xs ih =>
    intro ys; cases hfx : f x with
    | none   => simpa [List.mapM, hfx] using h
    | some y =>
      cases hxs : xs.mapM f with
      | none      => simpa [List.mapM, hfx, hxs] using h
      | some ys'  =>
        simp [List.mapM, hfx, hxs] at h
        cases h; simp [ih hxs]
```

**We already have this** in KernelExtras.lean at line 56! ‚úÖ

### Pattern 4: Membership ‚Üí Success

```lean
lemma mapM_some_of_mem {f : Œ± ‚Üí Option Œ≤}
    {xs : List Œ±} {ys : List Œ≤} {x : Œ±}
    (h : xs.mapM f = some ys) (hx : x ‚àà xs) :
    ‚àÉ b, f x = some b := by
  revert ys; induction xs with
  | nil => intro ys; cases hx
  | cons a as ih =>
    intro ys; cases hfa : f a with
    | none   => simpa [List.mapM, hfa] using h
    | some b =>
      cases hmap : as.mapM f with
      | none      => simpa [List.mapM, hfa, hmap] using h
      | some ys'  =>
        have := by simpa [List.mapM, hfa, hmap] using h
        cases this
        cases hx with
        | inl hx0 => subst hx0; exact ‚ü®b, hfa‚ü©
        | inr hx' => exact ih hmap hx'
```

**We already have this** in KernelExtras.lean at line 103! ‚úÖ

## Key Insight: Avoid mapM.loop

The proof patterns above work on Lean 4.20.0-rc2 because they:
- Never try to "simp through" the internal `mapM.loop`
- Stay at the two surface equations for `mapM` on `[]` and `x :: xs`
- Use `cases` to split on function results, then `simp [List.mapM, ...]`

**This is exactly what Oru≈æi implemented in KernelExtras!** üéØ

## How This Resolved Our Blocker

### Session 1: The Confusion
- `viewStack` was defined as `stk.toList.mapM toExpr`
- `toExpr` is total: `Formula ‚Üí Expr`
- But `viewStack` returns `Option (List Expr)`
- **Attempted 15+ proofs, all failed**

### Session 2: The Fix
- Changed to `stk.toList.mapM toExprOpt`
- `toExprOpt` is partial: `Formula ‚Üí Option Expr`
- **Type-level correctness achieved**
- Proof strategies became obvious

### The Validation
Expert confirms: "Pick Option A (use partial function). This aligns with your Phase-3 fail-fast refactor and TypedSubst."

**We made the right choice!** ‚úÖ

## About the Six "Foundation" Axioms

The expert notes: "Those should NOT stay axioms."

**Status in our codebase:**
1. ‚úÖ `mapM_length_option` - Fully proven (KernelExtras line 56)
2. ‚úÖ `mapM_some_of_mem` - Fully proven (KernelExtras line 103)
3. ‚úÖ `foldl_and_eq_true` - Fully proven (KernelExtras line 133)
4. ‚úÖ `foldl_all‚ÇÇ_true` - Fully proven (KernelExtras line 144)
5. ‚úÖ `Array.getBang_eq_get` - Fully proven (KernelExtras line 253)
6. ‚úÖ `Array.mem_toList_get` - Fully proven (KernelExtras line 237)

**All axioms are eliminated!** Oru≈æi's work is validated. üéØ

## Summary

**What we learned:**
- No automatic monad lifting exists in Lean 4
- Must explicitly choose monad and lift by hand
- Or use partial functions that match the target monad

**What we implemented:**
- Option A: Use `toExprOpt` with `mapM`
- Clean fail-fast semantics
- Type-correct at definition level

**What we validated:**
- KernelExtras proofs follow the expert-recommended patterns
- All six axioms are properly eliminated with proofs
- No reliance on `mapM.loop` internals

**Expert verdict:** "Keep going with phase 3!" ‚úÖ

---

**Bottom line:** Our Session 2 implementation is exactly right. The monad lifting mystery is solved, and we're using the expert-recommended patterns throughout. The foundation is solid! üöÄ
